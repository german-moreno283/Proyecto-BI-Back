{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c561be22-73dc-41a2-aa24-8eba8cdf0e83",
   "metadata": {},
   "source": [
    "# Análisis de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad2a53c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: num2words in c:\\users\\santi\\miniforge3\\lib\\site-packages (0.5.12)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\santi\\miniforge3\\lib\\site-packages (from num2words) (0.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5630835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import num2words\n",
    "import re, unicodedata, inflect\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay, RocCurveDisplay,\n",
    "    roc_auc_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31dd8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f934984",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECALL = \"Recall:\"\n",
    "PRECISION = \"Precision:\"\n",
    "F1 = \"F1:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6ed92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring pandas to show all cell content\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce5d02a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\santi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\santi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Downloading stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67b6048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ods_df = pd.read_csv(\"../data/cat_6716.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef070cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_df[\"sdg\"].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dee57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_df[\"Textos_espanol\"] = ods_df[\"Textos_espanol\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de32e53",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c2ddb",
   "metadata": {},
   "source": [
    "Para poder realizar el pre-procesamiento de los datos, es recomendable pasar por tres etapas:\n",
    "* Limpieza de los datos.\n",
    "* Tokenización.\n",
    "* Normalización.\n",
    "\n",
    "<span style=\"color:red\">!!! Antes de ver la solución, revisa alternativas para realizar las tres etapas previas.</span>\n",
    "\n",
    "Para mayor información, pueden consultar el [siguiente artículo](https://medium.com/datos-y-ciencia/preprocesamiento-de-datos-de-texto-un-tutorial-en-python-5db5620f1767\n",
    ")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124a94e",
   "metadata": {},
   "source": [
    "### Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e28f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    return [word.lower() for word in words]\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = num2words.num2words(int(word), lang='es')\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd89cc3",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_df[\"Textos_espanol\"] = ods_df[\"Textos_espanol\"].apply(word_tokenize).apply(preprocessing).apply(\" \".join)\n",
    "ods_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ed664",
   "metadata": {},
   "source": [
    "### Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da2af6",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The param 'stratify' is useful to guarantee label proportions on train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ods_df[[\"Textos_espanol\"]], ods_df[\"sdg\"], test_size=0.3, stratify=ods_df[\"sdg\"], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens = [nltk.word_tokenize(text) for text in X_train]\n",
    "X_test_tokens = [nltk.word_tokenize(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f133b",
   "metadata": {},
   "source": [
    "## Text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb551a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(tokenizer=word_tokenize, stop_words=stop_words, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f17c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = bow.fit_transform(X_train[\"Textos_espanol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03839a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stop_words, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c44fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(X_train[\"Textos_espanol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45d192",
   "metadata": {},
   "source": [
    "## Training a model with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model = RandomForestClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model.fit(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd311e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance in tree models is an indicator on how relevant is a feature for taking the decision by the model\n",
    "pd.Series(bow_model.feature_importances_, index=bow.vocabulary_).sort_values().tail(20).plot.barh(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fafaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_estimators = bow_model.estimators_\n",
    "print(\"Number of trees:\", len(bow_estimators))\n",
    "print(\"Trees depth (mean):\", np.mean([tree.get_depth() for tree in bow_estimators]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1eb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bow_predict = bow_model.predict(X_bow)\n",
    "y_test_bow_predict = bow_model.predict(bow.transform(X_test[\"Textos_espanol\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fefa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_bow_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_bow_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PRECISION, precision_score(y_train, y_train_bow_predict, average=\"weighted\"))\n",
    "print(RECALL, recall_score(y_train, y_train_bow_predict, average=\"weighted\"))\n",
    "print(F1, f1_score(y_train, y_train_bow_predict, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PRECISION, precision_score(y_test, y_test_bow_predict, average=\"weighted\"))\n",
    "print(RECALL, recall_score(y_test, y_test_bow_predict, average=\"weighted\"))\n",
    "print(F1, f1_score(y_test, y_test_bow_predict, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3415006",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "    (\"vectorizer\", CountVectorizer(tokenizer=word_tokenize, stop_words=stop_words, lowercase=True)),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=4)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eabc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"vectorizer\": [CountVectorizer(tokenizer=word_tokenize, stop_words=stop_words), TfidfVectorizer(tokenizer=word_tokenize, stop_words=stop_words)],\n",
    "    \"vectorizer__lowercase\": [True, False],\n",
    "    \"classifier__n_estimators\": [50, 100],\n",
    "    \"classifier__criterion\": ['gini', 'entropy'],\n",
    "    \"classifier__max_depth\": [25, 50, 75, 100], \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a09206",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipeline, param_grid, n_iter=10, scoring=[\"precision\", \"recall\", \"f1\"], refit=\"f1\", cv=7, return_train_score=True, verbose=1, random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train[\"Textos_espanol\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d086352",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_search_predict = search.best_estimator_.predict(X_train[\"Textos_espanol\"])\n",
    "y_test_search_predict = search.best_estimator_.predict(X_test[\"Textos_espanol\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PRECISION, precision_score(y_train, y_train_search_predict, average=\"weighted\"))\n",
    "print(RECALL, recall_score(y_train, y_train_search_predict, average=\"weighted\"))\n",
    "print(F1, f1_score(y_train, y_train_search_predict, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PRECISION, precision_score(y_test, y_test_search_predict, average=\"weighted\"))\n",
    "print(RECALL, recall_score(y_test, y_test_search_predict, average=\"weighted\"))\n",
    "print(F1, f1_score(y_test, y_test_search_predict, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd93bf",
   "metadata": {},
   "source": [
    "# Predicción y guardado de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbfd899",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_df_unlabeled = pd.read_csv(\"../data/SinEtiquetatest_cat_6716.csv\")\n",
    "#Predict the labels of the unlabeled data\n",
    "y_unlabeled_predict = search.best_estimator_.predict(ods_df_unlabeled[\"Textos_espanol\"])\n",
    "#Add the predicted labels to the unlabeled data\n",
    "ods_df_unlabeled[\"sdg\"] = y_unlabeled_predict\n",
    "#Save the labeled data\n",
    "ods_df_unlabeled.to_csv(\"../data/Predicted.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
